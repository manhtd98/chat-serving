name: "llama2"
platform: "onnxruntime_onnx"
max_batch_size: 1
input [
    {
        name: "input"
        data_type: TYPE_FP32
        dims: [3, 336, 224]
    }
]
output [
    {
        name: "output"
        data_type: TYPE_FP32
        dims: [4]
    }
]
instance_group [
    {
    count:1
    kind: KIND_GPU
    }
]
optimization { execution_accelerators {
  gpu_execution_accelerator : [ {
    name : "tensorrt"
    parameters { key: "precision_mode" value: "FP32" }
    parameters { key: "max_workspace_size_bytes" value: "1073741824" }}
  ]
}}